# es特点

es的有点：
1.横向可扩展性
2.分片机制提供更好的分布性
3.高可用性
4.使用简单


# 相关产品

* Beats：他是一个代理，将不同类型的数据发送到es中，Beats由三部分组成：FileBeat，TopBeat，PacketBeat
	* FileBeat用来收集日志
	* TopBeat用来收集系统基础设置数据，如CPU，内存，每个进程的统计信息
	* PackBeat是个网络包分析工具，统计收集网络信息
* Shield:他为es来带企业级的安全性，加密通信，认证保护整个es的数据，他是基于角色的访问控制与审计，但是他是收费的产品
* Watcher：是es的报警和通知工具，他可以主动监控es的状态，并在异常的时候进行提醒，但是他是收费产品
* Marvel:是es的监控和管理工具，他检测es集群索引和节点的活动，快速诊断问题，他是收费产品




# 倒排索引

假设现在有两篇文章：文章1和文章2

```
#文章1
Tom lives in guangzhou, I live guangzhou too.

#文章2
He once lived in Shanghai.

```

## 取得关键词

* 分词：即找出字符串中的所有单词，英文使用空格，中文使用特殊的分词处理
* 文章中的“in”，“once","two"等词没有什么实际的意义，中文中的“的”，“是”等词也是无具体含义，这些不代表概念的词是可以过滤掉的
* 所有的单词统一大小写，如"he","He"是一样的
* 去掉英文中的时态，如"lived","lives"都变成"live"
* 去掉文中的标点符号

在Lucene中以上措施有Analyzer类完成，进过上面的处理得到下面的结果：

```
#文章1
tom live guangzhou i live guangzhou

#文章2
he live shanghai

```


## 建立倒排索引

上面的对应关系是“文章号”对“文章中的所有的关键词”，倒排索引把这个关系倒过来，变成，“关键词”对“拥有该关键词的所有文章号”，如下表：

|关键词|文章号|
|-----|------|
|guangzhou|1|
|he|2|
|i|1|
|live|1,2|
|shanghai|2|
|tom|1|


通常知道关键词在哪些文章中出现的还不够，我们还需要知道关键词在文章中出现的次数和位置，通常有两种位置：
* 字符位置，记录该词在文章中的第几个关键词开始出现
* 关键词位置，记录该词是文章中的第几个关键词（出现的次数）

所以加上“出现频率”和“出现位置”之后，我们的索引结构如下表：

|关键词|文章号[出现频率]|出现位置|
|-----|------|---------------|
|guangzhou|1[2]|3,6|
|he|2[1]|1|
|i|1[1]|4|
|live|1[2], \n		2[1]|2,5 \n	2|
|shanghai|2[1]|3|
|tom|1[1]|1|

以“live”为例，说明一下该结构，live在文章1中出现了2次，文章2中出现了一次，那么“2，5”表示live在文章1中出现的两个位置（第几个关键词），剩下的2表示live在文章2中的第2个关键词出现


## 实现

实现时，Lucene将上面的三列分别作为字典文件（Term Directory），频率文件（frequencies),位置文件（positions)保存，其中字典文件不仅保存了每个关键词，还保存了指向频率文件和位置文件的指针，通过指正可以找到关键词的位置信息和频率信息

Lucene中使用filed的概念，用于表达信息所在位置（如标题中，文章中，URL中），在创建索引中，该field信息也记录在词典文件中，每个关键词都有一个field信息，因为每个关键词一定属于一个或多个filed。


## 压缩算法

为了减小索引文件的大小，Lucene还对索引文件使用了压缩技术
首先对词典文件中的关键词进行压缩，关键词压缩为<前缀长度，后缀>, 例如：当前词为“阿拉伯语”，上一个词为“阿拉伯”，那么“阿拉伯语”压缩为<3,语>

其次大量用到的是对数字的压缩，数字只保存与上一个数字的差值，（这样可以减少数字的长度，进而减少保存该数字所需要的字节数），例如当前文章号为16389（不要压缩用3个字节保存），上一文章号是16382，压缩后保存7（只用一个字节）

## 应用场景

下面我们可以通过对索引的查询来解释一下为什么要建立索引

假设我们要查询单词“live”， Luence先对词典二元查找，找到该词，通过指向频率的指针读出所有的文章号，然后返回结果，词典非常小，因而整个过程是毫秒级的

而用普通的顺序匹配算法，不建立索引，而是对所有文章进行字符串匹配，这个过程将会相当缓慢，当文章数目相当大时，时间往往是无法忍受的














