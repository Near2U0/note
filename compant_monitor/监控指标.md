# 1.flume监控指标

## 1.1.指标说明列表


|    指标说明 | 字段  |
| ---------- | --- |
| flume服务是否可用 |  http://172.16.14.35:34545/metrics  #or 看进程是否存在 |
| 成功接收并存入channel的数据量       |  EventTakeSuccessCount |
| 成功发送到kafka的数据量       |  EventDrainSuccessCount |
| 管道的填充率（用来判断是否有阻塞）|  ChannelFillPercentage |


## 1.2.获取方式

````
http://172.16.14.35:34545/metrics

```
![](/compant_monitor/imgs/compant_all.png)
![](compant_monitor/imgs/compant_all.png)
![](/note/compant_monitor/imgs/compant_all.png)

# 2.spark监控指标

1.spark服务是否可用
2.所有正在运行的作业（Application）
3.每个作业的所用的CPU core，memory
4.每个作业的处理时间--每个Batch的数据的处理耗时
5.每个作业的调度延迟--一个Batch在队列中阻塞住，等待上一个Batch完成处理的时间（如果Batch的处理时间，比Batch的间隔要长的话，而且调度延迟时间持续增长，应用程序不足以使用当前设定的速率来处理接收到的数据，此时可以考虑增加Batch的间隔时间）
6.GC时间

https://github.com/chenyansong1/note/blob/master/oldnote/bigdata/spark%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A_%E7%AC%94%E8%AE%B0/Spark%E8%BF%90%E7%BB%B4%E7%AE%A1%E7%90%86%E4%B9%8Bcurl+REST%20API%E4%BD%9C%E4%B8%9A%E7%9B%91%E6%8E%A7.md

example:

http://172.16.14.31:4040/api/v1/applications/app-20180223163123-0001


# 3.es监控指标

参见：
http://blog.csdn.net/u013613428/article/details/78179430
https://www.datadoghq.com/blog/collect-elasticsearch-metrics/


!()[/c/Users/landun/Desktop/monitor-metrics.png]

1.es坐在机器的CPU，内存，磁盘占用
2.集群健康和节点可用性

3.搜索和索引性能

4.搜索效果指标（查询性能）
搜索请求是Elasticsearch中的两个主要请求类型之一。（另一个是索引请求）。这些请求有时类似于传统数据库系统中的读写请求。Elasticsearch提供了与搜索过程的两个主要阶段（查询和获取）相对应的度量。

如果您使用Elasticsearch主要用于搜索，或者如果搜索是面向客户的主要功能，那么，您应该监视查询延迟并在超过阈值时采取行动。因此监视关于查询和提取的相关指标，对于帮助您确定搜索性能随时间的变化情况是很重要的。例如，您可能希望跟踪查询请求的尖峰和长期增长，以便您可以准备好调整配置以优化来获得更好的性能和可靠性。

5.索引性能指标（写入性能）
索引请求类似于传统数据库系统中的写入请求。

6.内存和垃圾收集
7.主机级别的系统和网络指标（待定）


# zk

1.服务是否可用
2.单机连接数
3.连接延时（最大，最小，平均）
4.记录日志的配置目录(conf)

```
#用于获取服务器端的运行状态:zk版本 打包信息,运行时角色,集群节点等
telnet localhost 2181 ,然后执行stat
#or
echo stat | nc localhost 2181

echo mntr |nc 172.16.14.31 2181

#服务是否OK （imok表示OK）
echo ruok|nc 127.0.0.1 2181
#or
/usr/hadoop/zookeeper-3.4.6/bin/zkServer.sh status
```



使用四字命令去查询

https://github.com/chenyansong1/note/blob/master/oldnote/bigdata/zookeeper/zookeeper%E5%9B%9B%E5%AD%97%E5%91%BD%E4%BB%A4.md

http://www.cnblogs.com/linuxbug/p/4840506.html


# hdfs
https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html#dfsadmin

hdfs dfsadmin -report 

1.磁盘总量/已使用
2.block的总量
3.遗失的block数量
4.存活的datanode和namenode数量/总量


查看节点的详细信息（相当于web页面展示的信息） hdfs    dfsadmin    -report


# kafka

1.服务是否可用
2.列出了所有消费者组的所有信息，包括Group(消费者组)、Topic、Pid(分区id)、Offset(当前已消费的条数)、LogSize(总条数)、Lag(未消费的条数)、Owner
3.每个topic的primary和replica数


http://blog.csdn.net/bluejoe2000/article/details/50487106
https://kafka.apache.org/documentation/#monitoring
http://jxauwxj.iteye.com/blog/2233925



# redis

1.服务是否正常：ping
2.info展示如下信息
2.1.连接的客户端数量
2.2.内存使用情况
2.3.CPU信息
2.4.stats信息



https://www.cnblogs.com/kaituorensheng/p/3979298.html
http://blog.csdn.net/qq_27623337/article/details/53206685



---

?
1.写脚本，还是写java程序
2.数据要入库到pg
http://www.cnblogs.com/qiongmiaoer/p/3346984.html
也可以参见：python写入pg的脚本

3.crontab定时任务

---



//to to list

1.修改告警状态确认		未做
2.脆弱性的显示详细		T_SIEM_LEAKSCAN


flume , zk，hdfs， redis , kafka, spark, es


kafka待定

