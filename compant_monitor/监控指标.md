监控组件的关系

![](/compant_monitor/imgs/compant_all.png)

下面是具体的监控指标说明


# 1.flume监控指标

## 1.1.指标说明列表


|    指标说明 | 字段  |
| ---------- | --- |
| flume服务是否可用 |  http://172.16.14.35:34545/metrics  #or 看进程是否存在 |
| 成功接收并存入channel的数据量       |  EventTakeSuccessCount |
| 成功发送到kafka的数据量       |  EventDrainSuccessCount |
| 管道的填充率（用来判断是否有阻塞）|  ChannelFillPercentage |


## 1.2.获取方式

```
http://172.16.14.35:34545/metrics
```


# 2.zk

|    指标说明 | 字段  |
| ---------- | --- |
| 服务是否可用 |  isok |
|单机连接数 |	zk_num_alive_connections|
| 连接延时（最大，最小，平均）|zk_min_latency,zk_avg_latency,zk_max_latency	|
| 记录日志的配置目录(conf)|	dataDir|
| 节点角色|zk_server_state	|

下面是获取指标的命令

1.ruok

```
[root@spark-slaver1 ~]# echo ruok |nc 172.16.14.31 2181|head -n 2|cut -f2
imok	
#imok表示服务OK，否则服务有问题
```

2.mntr，conf

```
[root@spark-slaver1 ~]# echo mntr |nc 172.16.14.31 2181
zk_version      3.4.6-1569965, built on 02/20/2014 09:09 GMT
zk_avg_latency  1
zk_max_latency  4242
zk_min_latency  0
zk_packets_received     34030
zk_packets_sent 34035
zk_num_alive_connections        2
zk_outstanding_requests 0
zk_server_state follower
zk_znode_count  2071
zk_watch_count  1
zk_ephemerals_count     3
zk_approximate_data_size        120046
zk_open_file_descriptor_count   34
zk_max_file_descriptor_count    65536

#####################

[root@spark-slaver1 ~]# echo conf |nc 172.16.14.31 2181
clientPort=2181
dataDir=/usr/hadoop/zookeeper-3.4.6/data/version-2
dataLogDir=/usr/hadoop/zookeeper-3.4.6/data/version-2
tickTime=2000
maxClientCnxns=60
minSessionTimeout=4000
maxSessionTimeout=40000
serverId=1
initLimit=10
syncLimit=5
electionAlg=3
electionPort=3888
quorumPort=2888
peerType=0
```

参考：
使用四字命令去查询
https://github.com/chenyansong1/note/blob/master/oldnote/bigdata/zookeeper/zookeeper%E5%9B%9B%E5%AD%97%E5%91%BD%E4%BB%A4.md

http://www.cnblogs.com/linuxbug/p/4840506.html



# 3.hdfs

## 3.1.指标说明列表


|    指标说明 | 字段  |
| ---------- | --- |
|服务是否存在|检查对应的进程|
| 磁盘总量/已使用/使用率 | Configured Capacity/DFS Used/DFS Used% |
| block的总量       |   |
| 遗失的block数量       | Missing blocks  |
| 存活的datanode和namenode数量/总量|   |


## 3.2.获取方式

通过调用jmx接口

```
#获取所有
http://172.16.14.31:50070/jmx
#可以使用过滤条件

#or
hdfs dfsadmin -report 
```

参看页面

> 页面总览

![](/compant_monitor/imgs/hdfs.png)

---

> DataNode页面

![](/compant_monitor/imgs/hdfs2.png)

---

> 获取方式

![](/compant_monitor/imgs/hdfs3.png)



# 4.redis

## 4.1.指标说明列表


|    指标说明 | 字段  |
| ---------- | --- |
| 服务是否正常 | ping  |
| 连接的客户端数量 | 见下面  |
| CPU/内存使用情况 |见下面   |
| stats信息 | 见下面  |


## 4.2.获取方式

```
echo -en  "auth 123456\r\nping\r\n"|nc 172.16.14.26 6379
echo -en  "auth 123456\r\ninfo\r\n"|nc 172.16.14.26 6379
```

---

> 下面是所有的指标

```

[root@spark-slaver1 ~]# echo -en  "auth 123456\r\ninfo\r\n"|nc 172.16.14.26 6379
+OK
$2274
# Server
redis_version:3.2.3
redis_git_sha1:00000000
redis_git_dirty:0
redis_build_id:b1dabfc1860e6863
redis_mode:standalone
os:Linux 3.10.0-327.el7.x86_64 x86_64
arch_bits:64
multiplexing_api:epoll
gcc_version:4.4.7
process_id:2721
run_id:bd78b529e4d89de105072f527173dd537c753c9e
tcp_port:6379
uptime_in_seconds:238973
uptime_in_days:2
hz:10
lru_clock:9664658
executable:/home/workspace/redis-3.2.3/src/redis-server
config_file:/home/workspace/redis-3.2.3/redis.conf

# Clients
connected_clients:13
client_longest_output_list:0
client_biggest_input_buf:0
blocked_clients:0

# Memory
used_memory:419148048
used_memory_human:399.73M
used_memory_rss:437653504
used_memory_rss_human:417.38M
used_memory_peak:423739136
used_memory_peak_human:404.11M
total_system_memory:134912073728
total_system_memory_human:125.65G
used_memory_lua:37888
used_memory_lua_human:37.00K
maxmemory:0
maxmemory_human:0B
maxmemory_policy:noeviction
mem_fragmentation_ratio:1.04
mem_allocator:jemalloc-4.0.3

# Persistence
loading:0
rdb_changes_since_last_save:0
rdb_bgsave_in_progress:0
rdb_last_save_time:1519580384
rdb_last_bgsave_status:ok
rdb_last_bgsave_time_sec:6
rdb_current_bgsave_time_sec:-1
aof_enabled:0
aof_rewrite_in_progress:0
aof_rewrite_scheduled:0
aof_last_rewrite_time_sec:-1
aof_current_rewrite_time_sec:-1
aof_last_bgrewrite_status:ok
aof_last_write_status:ok

# Stats
total_connections_received:15175
total_commands_processed:23594321
instantaneous_ops_per_sec:12
total_net_input_bytes:2329200155
total_net_output_bytes:110571009442
instantaneous_input_kbps:0.30
instantaneous_output_kbps:531.72
rejected_connections:0
sync_full:0
sync_partial_ok:0
sync_partial_err:0
expired_keys:0
evicted_keys:0
keyspace_hits:15006827
keyspace_misses:3132540
pubsub_channels:0
pubsub_patterns:0
latest_fork_usec:10294
migrate_cached_sockets:0

# Replication
role:master
connected_slaves:0
master_repl_offset:0
repl_backlog_active:0
repl_backlog_size:1048576
repl_backlog_first_byte_offset:0
repl_backlog_histlen:0

# CPU
used_cpu_sys:304.64
used_cpu_user:132.08
used_cpu_sys_children:61.15
used_cpu_user_children:616.42

# Cluster
cluster_enabled:0

# Keyspace
db0:keys=18,expires=0,avg_ttl=0
```

> 指标说明

https://www.cnblogs.com/kaituorensheng/p/3979298.html

http://blog.csdn.net/qq_27623337/article/details/53206685

https://github.com/chenyansong1/note/blob/master/oldnote/nosql/redis/redis%E8%BF%90%E7%BB%B4%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4.md



# 5.es监控指标

## 5.1.指标说明列表


|    指标说明 | 字段  |
| ---------- | --- |
| 服务是否正常 | ping  |
| es坐在机器的CPU，内存，磁盘占用 | 见下面  |
| 搜索效果指标 | 见下面  |
| 索引性能指标 | 见下面  |
| 集群健康和节点可用性 |见下面   |

3.搜索和索引性能

4.搜索效果指标（查询性能）
搜索请求是Elasticsearch中的两个主要请求类型之一。（另一个是索引请求）。这些请求有时类似于传统数据库系统中的读写请求。Elasticsearch提供了与搜索过程的两个主要阶段（查询和获取）相对应的度量。

如果您使用Elasticsearch主要用于搜索，或者如果搜索是面向客户的主要功能，那么，您应该监视查询延迟并在超过阈值时采取行动。因此监视关于查询和提取的相关指标，对于帮助您确定搜索性能随时间的变化情况是很重要的。例如，您可能希望跟踪查询请求的尖峰和长期增长，以便您可以准备好调整配置以优化来获得更好的性能和可靠性。

5.索引性能指标（写入性能）
索引请求类似于传统数据库系统中的写入请求。

6.内存和垃圾收集
7.主机级别的系统和网络指标（待定）


## 5.2.获取方式

> 搜索性能

http://172.16.14.21:9200/_nodes/TOFP0BeqSMKnhDFCxU-fdg/stats/indices/search
http://172.16.14.21:9200/syslog_20180226/_stats

> 索引性能

http://172.16.14.21:9200/_nodes/TOFP0BeqSMKnhDFCxU-fdg/stats/indices/indexing,refresh,flush
http://172.16.14.21:9200/syslog_20180226/_stats

> os(cpu,memory)

http://172.16.14.21:9200/_nodes/TOFP0BeqSMKnhDFCxU-fdg/stats/os

> disk

http://172.16.14.21:9200/_nodes/TOFP0BeqSMKnhDFCxU-fdg/stats/fs

> jvm

http://172.16.14.21:9200/_nodes/TOFP0BeqSMKnhDFCxU-fdg/stats/jvm

> 健康状态

http://172.16.14.21:9200/_cluster/health?pretty=true


具体的指标参见下图


![](/compant_monitor/imgs/monitor-metrics.png)



> 参考

http://blog.csdn.net/u013613428/article/details/78179430

https://www.datadoghq.com/blog/collect-elasticsearch-metrics/

---

# 6.kafka

## 6.1.指标说明列表


|    指标说明 | 说明  |
| ---------- | --- |
| 服务是否可用 | 监控进程是否存在  |
| 每个topic的primary和replica数 | 见下面：查看某个topic的详情  |
| 列出了所有消费者组的所有信息，包括Group(消费者组)、Topic、Pid(分区id)、Offset(当前已消费的条数)、LogSize(总条数)、Lag(未消费的条数)、Owner | 见下面  |



## 6.2.获取方式


```
#获取所有的topic，查看某个topic的详情
bin/kafka-topics.sh --list --zookeeper  soc31:2181
bin/kafka-topics.sh --topic syslog32 --describe --zookeeper soc31:2181

#查看所有的消费者组
bin/kafka-consumer-groups.sh --bootstrap-server soc35:9092 --list

#查看某个消费者组的消费情况
bin/kafka-consumer-groups.sh --bootstrap-server soc35:9092 --describe --group monitorwebsitegroup
```

> 参考

http://blog.csdn.net/bluejoe2000/article/details/50487106

https://kafka.apache.org/documentation/#monitoring

http://jxauwxj.iteye.com/blog/2233925


---


# 7.spark监控指标

## 7.1.指标说明列表

|    指标说明 | 说明  |
| ---------- | --- |
| spark服务 | master，worker进程是否存在 |
|  |   |
|  |   |
|  |   |




## 7.2.获取方式

2.所有正在运行的作业（Application）
3.每个作业的所用的CPU core，memory
4.每个作业的处理时间--每个Batch的数据的处理耗时
5.每个作业的调度延迟--一个Batch在队列中阻塞住，等待上一个Batch完成处理的时间（如果Batch的处理时间，比Batch的间隔要长的话，而且调度延迟时间持续增长，应用程序不足以使用当前设定的速率来处理接收到的数据，此时可以考虑增加Batch的间隔时间）
6.GC时间


1.streaming



2.单纯的spark作业（spark-sql）



https://github.com/chenyansong1/note/blob/master/oldnote/bigdata/spark%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A_%E7%AC%94%E8%AE%B0/Spark%E8%BF%90%E7%BB%B4%E7%AE%A1%E7%90%86%E4%B9%8Bcurl+REST%20API%E4%BD%9C%E4%B8%9A%E7%9B%91%E6%8E%A7.md

https://spark.apache.org/docs/latest/monitoring.html

f?status=[completed|running]

/applications	A list of all applications. 
?status=[completed|running] list only applications in the chosen state. 
 list only applications in the chosen state. 

example:

http://172.16.14.31:4040/api/v1/applications/app-20180223163123-0001

curl http://172.16.14.31:18080/api/v1/applications，

开启history server

https://callmesurprise.github.io/2016/11/13/Spark%E5%85%A5%E9%97%A8%20-%20history%20server/

---

?
1.写脚本，还是写java程序
2.数据要入库到pg
http://www.cnblogs.com/qiongmiaoer/p/3346984.html
也可以参见：python写入pg的脚本

3.crontab定时任务

---

像overview信息，只需要存储一条进行了，如果出现异常，只需要进行报警，没必要每隔一个时间段存储一条信息



//to to list

1.修改告警状态确认		未做
2.脆弱性的显示详细		T_SIEM_LEAKSCAN


flume , zk，hdfs， redis , kafka, spark, es


kafka待定


---

python 需要安装的环境


2、在Linux下执行curl https://bootstrap.pypa.io/get-pip.py | python 进行下载安装

这样很方便了  想装什么包就装什么包

Pip install xxx

