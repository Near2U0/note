监控组件的关系

![](/compant_monitor/imgs/compant_all.png)

下面是具体的监控指标说明


# 1.flume监控指标

## 1.1.指标说明列表


|    指标说明 | 字段  |
| ---------- | --- |
| flume服务是否可用 |  http://172.16.14.35:34545/metrics  #or 看进程是否存在 |
| 成功接收并存入channel的数据量       |  EventTakeSuccessCount |
| 成功发送到kafka的数据量       |  EventDrainSuccessCount |
| 管道的填充率（用来判断是否有阻塞）|  ChannelFillPercentage |


## 1.2.获取方式

```
http://172.16.14.35:34545/metrics
```


# 2.zk

|    指标说明 | 字段  |
| ---------- | --- |
| 服务是否可用 |  isok |
|单机连接数 |	zk_num_alive_connections|
| 连接延时（最大，最小，平均）|zk_min_latency,zk_avg_latency,zk_max_latency	|
| 记录日志的配置目录(conf)|	dataDir|
| 节点角色|zk_server_state	|

下面是获取指标的命令

1.ruok

```
[root@spark-slaver1 ~]# echo ruok |nc 172.16.14.31 2181|head -n 2|cut -f2
imok	
#imok表示服务OK，否则服务有问题
```

2.mntr，conf

```
[root@spark-slaver1 ~]# echo mntr |nc 172.16.14.31 2181
zk_version      3.4.6-1569965, built on 02/20/2014 09:09 GMT
zk_avg_latency  1
zk_max_latency  4242
zk_min_latency  0
zk_packets_received     34030
zk_packets_sent 34035
zk_num_alive_connections        2
zk_outstanding_requests 0
zk_server_state follower
zk_znode_count  2071
zk_watch_count  1
zk_ephemerals_count     3
zk_approximate_data_size        120046
zk_open_file_descriptor_count   34
zk_max_file_descriptor_count    65536

#####################

[root@spark-slaver1 ~]# echo conf |nc 172.16.14.31 2181
clientPort=2181
dataDir=/usr/hadoop/zookeeper-3.4.6/data/version-2
dataLogDir=/usr/hadoop/zookeeper-3.4.6/data/version-2
tickTime=2000
maxClientCnxns=60
minSessionTimeout=4000
maxSessionTimeout=40000
serverId=1
initLimit=10
syncLimit=5
electionAlg=3
electionPort=3888
quorumPort=2888
peerType=0
```

参考：
使用四字命令去查询
https://github.com/chenyansong1/note/blob/master/oldnote/bigdata/zookeeper/zookeeper%E5%9B%9B%E5%AD%97%E5%91%BD%E4%BB%A4.md

http://www.cnblogs.com/linuxbug/p/4840506.html



# 3.hdfs

## 3.1.指标说明列表


|    指标说明 | 字段  |
| ---------- | --- |
| 磁盘总量/已使用/使用率 | Configured Capacity/DFS Used/DFS Used% |
| block的总量       |   |
| 遗失的block数量       | Missing blocks  |
| 存活的datanode和namenode数量/总量|   |


## 3.2.获取方式

```
hdfs dfsadmin -report 

#一些指标，可能需要web页面爬
```



通过调用jmx接口

```
#获取所有
http://172.16.14.31:50070/jmx

#可以使用过滤条件
```

参看页面
页面总览
![](/compant_monitor/imgs/hdfs.png)

---

DataNode页面
![](/compant_monitor/imgs/hdfs2.png)

---

获取方式

![](/compant_monitor/imgs/hdfs3.png)



查看节点的详细信息（相当于web页面展示的信息） hdfs    dfsadmin    -report

```
[root@soc31 zookeeper-3.4.6]# hdfs dfsadmin -report 
#总的概况
Configured Capacity: 3482066092032 (3.17 TB)		
Present Capacity: 2147042626550 (1.95 TB)
DFS Remaining: 2145248514048 (1.95 TB)
DFS Used: 1794112502 (1.67 GB)
DFS Used%: 0.08%
Under replicated blocks: 0
Blocks with corrupt replicas: 0
Missing blocks: 0

#查看每个节点的详情
-------------------------------------------------
Live datanodes (3):

Name: 172.16.14.33:50010 (soc33)
Hostname: soc33
Decommission Status : Normal
Configured Capacity: 1153172504576 (1.05 TB)
DFS Used: 798143580 (761.17 MB)
Non DFS Used: 278671686564 (259.53 GB)
DFS Remaining: 873702674432 (813.70 GB)
DFS Used%: 0.07%
DFS Remaining%: 75.77%
Configured Cache Capacity: 0 (0 B)
Cache Used: 0 (0 B)
Cache Remaining: 0 (0 B)
Cache Used%: 100.00%
Cache Remaining%: 0.00%
Xceivers: 1
Last contact: Mon Feb 26 09:07:59 CST 2018


Name: 172.16.14.32:50010 (soc32)
Hostname: soc32
Decommission Status : Normal
Configured Capacity: 1153172504576 (1.05 TB)
DFS Used: 560182107 (534.23 MB)
Non DFS Used: 293609974949 (273.45 GB)
DFS Remaining: 859002347520 (800.01 GB)
DFS Used%: 0.05%
DFS Remaining%: 74.49%
Configured Cache Capacity: 0 (0 B)
Cache Used: 0 (0 B)
Cache Remaining: 0 (0 B)
Cache Used%: 100.00%
Cache Remaining%: 0.00%
Xceivers: 1
Last contact: Mon Feb 26 09:07:59 CST 2018


Name: 172.16.14.31:50010 (soc31)
Hostname: soc31
Decommission Status : Normal
Configured Capacity: 1175721082880 (1.07 TB)
DFS Used: 435786815 (415.60 MB)
Non DFS Used: 762741803969 (710.36 GB)
DFS Remaining: 412543492096 (384.21 GB)
DFS Used%: 0.04%
DFS Remaining%: 35.09%
Configured Cache Capacity: 0 (0 B)
Cache Used: 0 (0 B)
Cache Remaining: 0 (0 B)
Cache Used%: 100.00%
Cache Remaining%: 0.00%
Xceivers: 1
Last contact: Mon Feb 26 09:08:00 CST 2018

```


https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HDFSCommands.html#dfsadmin


# 2.spark监控指标

1.spark服务是否可用
2.所有正在运行的作业（Application）
3.每个作业的所用的CPU core，memory
4.每个作业的处理时间--每个Batch的数据的处理耗时
5.每个作业的调度延迟--一个Batch在队列中阻塞住，等待上一个Batch完成处理的时间（如果Batch的处理时间，比Batch的间隔要长的话，而且调度延迟时间持续增长，应用程序不足以使用当前设定的速率来处理接收到的数据，此时可以考虑增加Batch的间隔时间）
6.GC时间

https://github.com/chenyansong1/note/blob/master/oldnote/bigdata/spark%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E7%B2%BE%E9%80%9A_%E7%AC%94%E8%AE%B0/Spark%E8%BF%90%E7%BB%B4%E7%AE%A1%E7%90%86%E4%B9%8Bcurl+REST%20API%E4%BD%9C%E4%B8%9A%E7%9B%91%E6%8E%A7.md

example:

http://172.16.14.31:4040/api/v1/applications/app-20180223163123-0001


# 3.es监控指标

参见：
http://blog.csdn.net/u013613428/article/details/78179430
https://www.datadoghq.com/blog/collect-elasticsearch-metrics/


!()[/c/Users/landun/Desktop/monitor-metrics.png]

1.es坐在机器的CPU，内存，磁盘占用
2.集群健康和节点可用性

3.搜索和索引性能

4.搜索效果指标（查询性能）
搜索请求是Elasticsearch中的两个主要请求类型之一。（另一个是索引请求）。这些请求有时类似于传统数据库系统中的读写请求。Elasticsearch提供了与搜索过程的两个主要阶段（查询和获取）相对应的度量。

如果您使用Elasticsearch主要用于搜索，或者如果搜索是面向客户的主要功能，那么，您应该监视查询延迟并在超过阈值时采取行动。因此监视关于查询和提取的相关指标，对于帮助您确定搜索性能随时间的变化情况是很重要的。例如，您可能希望跟踪查询请求的尖峰和长期增长，以便您可以准备好调整配置以优化来获得更好的性能和可靠性。

5.索引性能指标（写入性能）
索引请求类似于传统数据库系统中的写入请求。

6.内存和垃圾收集
7.主机级别的系统和网络指标（待定）







# kafka

1.服务是否可用
2.列出了所有消费者组的所有信息，包括Group(消费者组)、Topic、Pid(分区id)、Offset(当前已消费的条数)、LogSize(总条数)、Lag(未消费的条数)、Owner
3.每个topic的primary和replica数


http://blog.csdn.net/bluejoe2000/article/details/50487106
https://kafka.apache.org/documentation/#monitoring
http://jxauwxj.iteye.com/blog/2233925



# redis

1.服务是否正常：ping
2.info展示如下信息
2.1.连接的客户端数量
2.2.内存使用情况
2.3.CPU信息
2.4.stats信息



https://www.cnblogs.com/kaituorensheng/p/3979298.html
http://blog.csdn.net/qq_27623337/article/details/53206685



---

?
1.写脚本，还是写java程序
2.数据要入库到pg
http://www.cnblogs.com/qiongmiaoer/p/3346984.html
也可以参见：python写入pg的脚本

3.crontab定时任务

---



//to to list

1.修改告警状态确认		未做
2.脆弱性的显示详细		T_SIEM_LEAKSCAN


flume , zk，hdfs， redis , kafka, spark, es


kafka待定

