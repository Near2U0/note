---
title: 传统的IO原理
categories: socket   
tags: [socket]
---




下图简单描述了数据从外部磁盘向运行中的进程的内存区域移动的过程。
1. 进程使用read( )系统调用，要求其缓冲区被填满。
2. 内核随即向磁盘控制硬件发出命令，要求其从磁盘读取数据。
3. 磁盘控制器把数据直接写入内核内存缓冲区，这一步通过DMA完成，无需主CPU协助。
4. 一旦磁盘控制器把缓冲区装满，内核即把数据从内核空间的临时缓冲区拷贝到进程执行read( )调用时指定的缓冲区


![](http://ols7leonh.bkt.clouddn.com//assert/img/java/socket/IO_1.png)



注意图中用户空间和内核空间的概念。用户空间是常规进程所在区域。 JVM就是常规进程，驻守于用户空间。用户空间是非特权区域：比如，在该区域执行的代码就不能直接访问硬件设备。
内核空间是操作系统所在区域。内核代码有特别的权力：它能与设备控制器通讯，控制着用户区域进程的运行状态，等等。最重要的是，所有I/O都直接（如这里所述）或间接通过内核空间。


当进程请求I/O操作的时候，它执行一个系统调用（有时称为陷阱）将控制权移交给内核。C/C++程序员所熟知的底层方法open( )、 read( )、 write( )和close( )要做的无非就是建立和执行适当的系统调用。当内核以这种方式被调用，它随即采取任何必要步骤，找到进程所需数据，并把数据传送到用户空间内的指定缓冲区。内核试图对数据进行高速缓存或预读取，因此进程所需数据可能已经在内核空间里了。如果是这样，该数据只需简单地拷贝出来即可。如果数据不在内核空间，则进程被挂起，内核着手把数据读进内存。看了图 1-1， 您可能会觉得，把数据从内核空间拷贝到用户空间似乎有些多余。


为什么不直接让磁盘控制器把数据送到用户空间的缓冲区呢？这样做有几个问题。首先，硬件通常不能直接访问用户空间 ，其次，像磁盘这样基于块存储的硬件设备操作的是固定大小的数据块，而用户进程请求的可能是任意大小的或非对齐的数据块。在数据往来于用户空间与存储设备的过程中，内核负责数据的分解、再组合工作，因此充当着中间人的角色。



# 2.虚拟内存
虚拟内存意为使用虚假（或虚拟）地址取代物理（硬件RAM）内存地址。把内核空间地址与用户空间的虚拟地址映射到同一个物理地址，这样，DMA硬件（只能访问物理内存地址）就可以填充对内核与用户空间进程同时可见的缓冲区（见图），这样做好处颇多，总结起来可分为两大类：
1. 一个以上的虚拟地址可指向同一个物理内存地址。
2. 虚拟内存空间可大于实际可用的硬件内存。

![](http://ols7leonh.bkt.clouddn.com//assert/img/java/socket/IO_2.png)


这样真是太好了，省去了内核与用户空间的往来拷贝，但前提条件是，内核与用户缓冲区必须使用相同的页对齐，缓冲区的大小还必须是磁盘控制器块大小（通常为 512 字节磁盘扇区）的倍数。操作系统把内存地址空间划分为页，即固定大小的字节组。内存页的大小总是磁盘块大小的倍数，通常为 2 次幂（这样可简化寻址操作）