# 1.sparkContext 的初始化的过程

* taskScheduler的创建(注册application，调度池问题)
* backend
* spark UI
* dagScheduler 

driver 的由来

1. 在sparkcontext创建的时候，会创建一个

```
val (sched, ts) = SparkContext.createTaskScheduler(this, master, deployMode)
// 这个方法会返回一个schedulerBackend，和TaskSchedulerImpl

schedulerBackend 有具体的 实现类， 。。。。 ，他负责向Master注册，接收Executor的反注册，将task发送到Executor等操作


SparkContext.createTaskScheduler在方法内部生成了TaskSchedulerImpl，然后会调用TaskSchedulerImpl的initialize,这里会创建一个调度池，（两种不同类型的调度池：FIFO,FAIR），


接着sparkcontext向下走

_taskScheduler.start()


    _taskScheduler.start() // _taskScheduler 里面有一个backend，这个backend启动会去启动 driver，并让driver向Master注册
这里会涉及到：Driver向Master注册

```


2. sparkContext在创建的时候，同时会创建 dagScheduler，其底层的是依赖DAGSchedulerEventProcessLoop进行通信（核心）

3. spark UI 在此时创建，默认访问404端口


# 2.Master的主备切换

spark内核源码二之Master原理解析


# 3.Master的注册机制

1.worker的注册
2.driver的注册

Master.receiveAndReply() 方法中有对应的方法


3.application的注册

这个是backend内部的APPClient向Master发送RegisterApplication

Master.receive() 方法中

waitingApps中存放的是等待的application，在schedule()方法调用的时候，会从waitingApps中取出一个一个的application，然后为这些application去启动Executor



![](/Users/chenyansong/Documents/note/img/bigdata/spark从入门到精通_笔记/master的注册机制.png)


# 4.Master状态改变处理机制原理剖析与源码分析

1.DriverStateChanged

```
# 如果driver的状态是下面中的几种，那么会将driver移除
case DriverState.ERROR | DriverState.FINISHED | DriverState.KILLED |    DriverState.FAILED =>
          removeDriver(driverId, state, exception)
```

2.ExecutorStateChanged


# 5.mater中的schedule方法的调用

1.为每个Worker分配core（这里有两种分配算法，一种是尽可能的将多个core分配到少的Worker上，另一种是尽可能的将core分配到多个Worker上）

2.去特定的worker上去启动Executor


# 6.worker

1.对于yarn-cluster模式，driver的启动过程
2.对于Executor的启动过程
    CoarseGrainedExecutorBackend 是一个Executor的后台进程，在其启动的时候，就会想Driver进行注册


![](/Users/chenyansong/Documents/note/img/bigdata/spark从入门到精通_笔记/Worker原理解析及源码分析.png)


# 7.job触发流程原理

下面是一个简单的Wordcount的，我们来看下其触发原理

```

val lines = sc.textFile()
val words = lines.flatMap(line=>line.split(" "))
val pairs = words.map(word=>(word,1))
val touple = pairs.reduceByKey(_+_)

touple.foreach(t=>println(t._1+":"+t._2))

/*
在spark的action操作的最后，会反复的调用sparkContext的runJob方法，
最终 会调用dagScheduler.runJob方法

*/
```

# 8. dagscheduler的调度算法

1.这里会涉及到stage的划分算法，特别是如果是一个action所造成的stage，这里会有三个RDD


![](/Users/chenyansong/Documents/note/img/bigdata/spark从入门到精通_笔记/stage.png)

2.task的最佳位置 寻找

# 9.taskScheduler的提交
1.本地化
2.task的提交


# 10.Executor上task的启动


1.Executor的注册机制
2.task的启动机制

在CoarseGrainedExecutorBackend初始化的时候，会向Driver反向注册（发送RegisterExecutor），在Driver端，接收到RegisterExecutor消息之后，会向Executor发送RegisteredExecutor消息，然后在CoarseGrainedExecutorBackend中接收到RegisteredExecutor消息，会new Executor，


# 11.task的运行原理

1.run方法


# 12.shuffle原理

从shuffle的原理可以知道，所谓的内存计算，只不过是在Stage内部，所有的transform是基于内存的迭代，但是在shuffle与shuffle之间，还是需要将上一次shuffle计算的结果写入本地磁盘，然后等待下一个shuffle的开始的RDD去拉取，