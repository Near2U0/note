[toc]





# 安装及配置

https://www.dazhuanlan.com/2020/03/26/5e7bb2bf85c0d/



```shell
#添加字段
ALTER TABLE visits ADD COLUMN browser String AFTER user_id

#建表
CREATE TABLE tutorial.threat_iocs
(
    `threat_id` UInt32,
    `category` String,
    `category_name` String,
    `created_time` DateTime,
    `item` String,
    `geo` String,
    `score` String
)
ENGINE = MergeTree()
ORDER BY (threat_id)


```





# 离线安装

```shell
#一定安装stable的版本
#参考：https://clickhouse.tech/docs/zh/getting-started/install/

export LATEST_VERSION=`curl https://api.github.com/repos/ClickHouse/ClickHouse/tags 2>/dev/null | grep -Eo '[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+' | head -n 1`
curl -O https://repo.clickhouse.tech/tgz/clickhouse-common-static-$LATEST_VERSION.tgz
curl -O https://repo.clickhouse.tech/tgz/clickhouse-common-static-dbg-$LATEST_VERSION.tgz
curl -O https://repo.clickhouse.tech/tgz/clickhouse-server-$LATEST_VERSION.tgz
curl -O https://repo.clickhouse.tech/tgz/clickhouse-client-$LATEST_VERSION.tgz

tar -xzvf clickhouse-common-static-$LATEST_VERSION.tgz
sudo clickhouse-common-static-$LATEST_VERSION/install/doinst.sh

tar -xzvf clickhouse-common-static-dbg-$LATEST_VERSION.tgz
sudo clickhouse-common-static-dbg-$LATEST_VERSION/install/doinst.sh

tar -xzvf clickhouse-server-$LATEST_VERSION.tgz
sudo clickhouse-server-$LATEST_VERSION/install/doinst.sh
sudo /etc/init.d/clickhouse-server start

tar -xzvf clickhouse-client-$LATEST_VERSION.tgz
sudo clickhouse-client-$LATEST_VERSION/install/doinst.sh


#启动
sudo /etc/init.d/clickhouse-server start

```



# 自定义分区

```shell
#分区的目录结构
#https://clickhouse.tech/docs/zh/engines/table-engines/mergetree-family/custom-partitioning-key/
#http://www.clickhouse.com.cn/topic/5b2ccbb49d28dfde2ddc6193
```

![](../../../images/bigdata/clickhouse/75c878daf5de2a56d724e00bf4ad8c82.png)

```
其中：
default：数据库名
test_analysis：表名
20180424_20180424_1_6_1：是一个part，每次插入数据就会生成一个part，part会不定时的merge成更大的一个part，每个part里的数据都是按照主键排序存储的
checksums.txt：校验值文件
columns.txt：列名文件，记录了表中的所有列名
column_name.mrk：每个列都有一个mrk文件
column_name.bin：每个列都有一个bin文件，里边存储了压缩后的真实数据
primary.idx：主键文件，存储了主键值

primary.idx存储的数据结构类似于一系列marks组成的数组，这里的marks就是每隔index_granularity行取的主键值，一般默认index_granularity=8192
column_name.mrk文件中也类似于primark.key，每隔 index_granularity行就会记录一次offset。
primark.idx和column_name.mrk文件做了逻辑行的映射关系
当接收到查询操作时，首先在primary.idx中选出数据的大概范围，然后在column_name.mrk中得到对应数据的offset，根据offset将bin文件中的数据加载到内存，做真正的数据过滤得到查询结果
```



# 修改数据目录

clickhouse的默认的数据

```shell
/usr/local/clickhouse-server-20.10.6.27


#当前的安装路径
[root@bdsoc clickhouse-server-20.10.6.27]# pwd
/usr/local/clickhouse-server-20.10.6.27

#目录构成
[root@bdsoc clickhouse-server-20.10.6.27]# ll
总用量 16
drwxr-xr-x 6 root root 4096 12月 14 15:27 etc
drwxr-xr-x 2 root root 4096 12月 14 17:58 install
drwxr-xr-x 3 root root 4096 12月  5 22:38 lib
drwxr-xr-x 4 root root 4096 12月  5 22:38 usr


#将下面的路径的:/var/lib/全部换成你的数据目录
#需要修改的文件：doinst.sh
[root@bdsoc clickhouse-server-20.10.6.27]# ll install/
总用量 20
-rwxr-xr-x 1 root root  387 12月  5 23:26 delete.sh
-rwxr-xr-x 1 root root 7195 12月 14 17:58 doinst.sh
-rwxr-xr-x 1 root root  174 12月  5 23:26 predelete.sh
-rwxr-xr-x 1 root root  153 12月  5 23:26 predoinst.sh

#需要修改的文件：config.xml 
[root@bdsoc clickhouse-server-20.10.6.27]# ll etc/clickhouse-server/
总用量 44
-rw-r--r-- 1 root root 35891 12月 14 17:59 config.xml
-rw-r--r-- 1 root root  5587 12月  5 21:54 users.xml
[root@bdsoc clickhouse-server-20.10.6.27]# 

```



应用：

https://zhuanlan.zhihu.com/p/103781296?utm_source=wechat_timeline



可视化工具

clickhouse的可视化工具DEeaver ： https://www.cnblogs.com/cbugs/p/13358246.html

jdbc入库：https://github.com/ClickHouse/clickhouse-jdbc



spring-boot的集成



跨域的问题：https://www.cnblogs.com/shaoniandream/p/10511262.html



