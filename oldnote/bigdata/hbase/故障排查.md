
问题通常出现在那些基本设置失误的集群上，如果集群出现了问题，首先要做的就是分析主节点日志文件，因为主节点为集群提供了协调服务，如果幸运的话，只要在日志文件中找到一些警告或错误信息，就能找到问题的根本原因

regionServer的日志是另一个需要检查的信息源，regionServer的日志文件通常包含一些与负载相关的错误的日志，因为regionServer要为集群处理具体的数据存储和访问操作

hbase运行在HDFS之上，他要依靠zookeeper来作为自己的协调服务，有时，我们还需要检查一下hdfs，MapReduce和zookeeper的日志，在默认情况下，所有这些日志文件都在安装文件夹阿德logs目录下，当然，该位置可以在log4j属性文件中配置



# 故障排查工具介绍

下面推荐几种故障排查工具

* ps:该工具可以用来查找内容和CPU最多的有哪些进程
* ClusterSSH工具：可以用来同时控制多个SSH会话
* jps:可以显示当前用户的Java进程
* jmap:可以打印出Java堆的概要信息
* jstat：这是一个Java虚拟机的统计监测工具
* Hbase hbck:可以用来检查并修复区域一致性和表完整性方面的问题
* Hadoop fsck：可以用于检查hdfs的一致性问题

## ps

该工具可以用来找到占用内存量最大的进程

```
[root@hdp-node-01 conf]# ps auxk -rss|less
USER        PID		%CPU %MEM    VSZ   RSS   TTY      STAT   START   TIME 			  COMMAND
root      10560		 1.3 14.8 1636316 282992 ?      	S		l  	12:02   2:30 	  org.apache.hadoop.hdfs.server.datanode.DataNode
root      10456		 1.5 13.0 1627940 248732 ?      	S		l  	12:02   2:47 	  org.apache.hadoop.hdfs.server.namenode.NameNode
root      10750		 0.5 11.8 1605316 226236 ?      	S		l  	12:02   1:03 	  org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode
root       9813		 0.6  4.2 2590584 81304  pts/1      S		l  	11:50   1:16 	  org.apache.zookeeper.server.quorum.QuorumPeerMain 


#a:表示所有的进程
#u：表示用户list
#x:采用旧式的Linux i386登陆格式显示程序状况。
#k:表示排序，后面的-rss就是指定排序的字段
#rss: resident set size
#vsize: total VM size in kB
 
```

## jps

查看当前用户的Java进程

```
[root@hdp-node-01 conf]# jps
10750 SecondaryNameNode
10560 DataNode
10456 NameNode
13505 Jps
9813 QuorumPeerMain

```

## jmap打印Java堆的概要信息

如：通过上面的jps可以看出NameNode的pid是10456，那么可以使用jmap打印其堆概要信息，如下 ：

```
[root@hdp-node-01 conf]# jmap -heap 10456
Attaching to process ID 10456, please wait...
Debugger attached successfully.
Server compiler detected.
JVM version is 24.80-b11

using thread-local object allocation.
Parallel GC with 4 thread(s)

Heap Configuration:
   MinHeapFreeRatio = 0
   MaxHeapFreeRatio = 100
   MaxHeapSize      = 1048576000 (1000.0MB)
   NewSize          = 1310720 (1.25MB)
   MaxNewSize       = 17592186044415 MB
   OldSize          = 5439488 (5.1875MB)
   NewRatio         = 2
   SurvivorRatio    = 8
   PermSize         = 21757952 (20.75MB)
   MaxPermSize      = 85983232 (82.0MB)
   G1HeapRegionSize = 0 (0.0MB)

Heap Usage:
PS Young Generation
Eden Space:
   capacity = 80740352 (77.0MB)
   used     = 18454776 (17.59984588623047MB)
   free     = 62285576 (59.40015411376953MB)
   22.856942709390218% used
From Space:
   capacity = 5242880 (5.0MB)
   used     = 4829280 (4.605560302734375MB)
   free     = 413600 (0.394439697265625MB)
   92.1112060546875% used
To Space:
   capacity = 6815744 (6.5MB)
   used     = 0 (0.0MB)
   free     = 6815744 (6.5MB)
   0.0% used
PS Old Generation
   capacity = 40370176 (38.5MB)
   used     = 19595680 (18.687896728515625MB)
   free     = 20774496 (19.812103271484375MB)
   48.53999150263799% used
PS Perm Generation
   capacity = 37224448 (35.5MB)
   used     = 32904440 (31.38011932373047MB)
   free     = 4320008 (4.119880676269531MB)
   88.39470232036751% used
```

## jstat

这是一个Java虚拟机的统计监测工具，运行下面的命令可以显示NameNode进程在垃圾回收方面的各种统计指标的概要信息

```
[root@hdp-node-01 conf]# jstat -gcutil 10456 1000
  S0     S1     E      O      P     YGC     YGCT    FGC    FGCT     GCT   
  0.00  92.11  39.59  48.54  88.43     19    2.136     1    0.207    2.343
  0.00  92.11  39.59  48.54  88.43     19    2.136     1    0.207    2.343
  0.00  92.11  39.59  48.54  88.43     19    2.136     1    0.207    2.343
  0.00  92.11  39.59  48.54  88.43     19    2.136     1    0.207    2.343
  0.00  92.11  39.59  48.54  88.43     19    2.136     1    0.207    2.343
  0.00  92.11  39.63  48.54  88.43     19    2.136     1    0.207    2.343

# 10456是pid,1000是ms,表示每隔1s采集一次

```

# 处理“打开的文件过多”错误

有时在 DataNode日志中会出现如下的错误

```
java.io.FileNotFoundException: /usr/local/hadoop/var/dfs/data/current/subdir6/blk_-888823434243241342 (Too many open files)

```

## 操作

要解决文件打开过多的错误，需要在集群的每个结点上执行一遍如下的命令：

1.增加hadoop用户可打开文件的个数

vim /etc/security/limits.conf 
```
hadoop	soft nofile 65535
hadoop	hard nofile 65535

```

2.在/etc/pam.d/login文件中添加如下行

vim /etc/pam.d/login
```
session required pam_limits.so

```


3.退出登录，然后再次以Hadoop用户的身份重新登录

4.查看可打开文件数的限制

```
ulimit -n
65535
```

5.重启hdfs和hbase

```
$HBASE_HOME/bin/stop-hbase.sh
$HADOOP_HOME/bin/stop-dfs.sh

$HADOOP_HOME/bin/start-dfs.sh
$HBASE_HOME/bin/start-hbase.sh

```


## 原理

hbase是运行在Hadoop上的数据库，和其他数据库一样，他也要同时打开很多个文件，另一方面，linux对于一个进程可以打开的文件描述符的个数有所限制，默认限制为1024，这对于hbase来说太小了，如果Hadoop用户所打开的文件超过了此上限，DataNode日志中就会出现一条“Too many open files”的错误信息


* 在第1步中，设置了Hadoop用户可以打开文件数的限制
* 在第2步中，修改了/etc/pam.d/login文件，这些修改会在用户下一次登录进系统之后生效，（soft nofile）是操作系统内核强制限制的可打开文件描述符的个数，（hard nofile)是软限制的上限
* ulimit -n可以查看当前用户的可打开文件个数的上限

## 补充说明

如果你想知道hadoop用户当前已经打开的文件的个数，可以使用lsof

```
lsof -uhadoop | wc -l
```

# 处理“无法创建新本地线程”错误

## 错误描述

在regionServer的日志中出现如下的错误

```
DataStreamer Exception：java.lang.OutOfMemoryError：unable to create new native thread

```

## 操作步骤

假设我们是以hadoop用户启动的hbase

需要在集群的每个结点上执行以下的步骤

1.提高hadoop用户可打开进程数的最大值

vim /etc/security/limits.conf
```
hadoop soft nproc 32000
hadoop hard nproc 32000

```

2.在/etc/pam.d/login文件中添加如下行

vim /etc/pam.d/login

```
session required pam_limits.so

```

3.当前用户退出登录，然后再次以hadoop用户重新登录

4.查看可打开进程数的最大值

```
ulimit -u
32000

```


5.重启hdfs和hbase

```
$HBASE_HOME/bin/stop-hbase.sh
$HADOOP_HOME/bin/stop-dfs.sh

$HADOOP_HOME/bin/start-dfs.sh
$HBASE_HOME/bin/start-hbase.sh

```


## 补充说明

若要查看hadoop用户的当前线程数，执行下面的命令：

```
#显示所有
ps -o pid,comm,user,thcount -u hadoop


#统计个数
[root@hdp-node-03 ~]# ps -o pid,comm,user,thcount -u root|wc -l
121
```


# 处理“hbase忽略hdfs客户端配置”问题

你可能已经注意到hbase忽略了你的hdfs客户端配置信息，例如：dfs.replication设置，在本例中，我们已将hdfs客户端的复制因子设为了4

vim $HADOOP_HOME/etc/hadoop/hdfs-site.xml
```
 <property>
         <name>dfs.replication</name>
         <value>4</value>
 </property>
```


然后在hbase的web界面看到的还是3（hdfs复制因子的默认值）

![](/images/bigdata/hbase/dfs_replication.jpg)


所以这并不是我们期望的结果，我们期望的实际值是4

下面是这种现象的解决办法

## 操作步骤

思路：将hadoop的hdfs-site.xml文件做一个软连接到hbase的conf目录下面

1.添加hdfs-site.xml文件的软连接到hbase的conf目录下面

```
[root@hdp-node-01 conf]# ln -s /bigdata_installed/hadoop/etc/hadoop/hdfs-site.xml /bigdata_installed/hbase/conf/hdfs-site.xml
[root@hdp-node-01 conf]# pwd
/bigdata_installed/hbase/conf
[root@hdp-node-01 conf]# ll
total 40
-rw-r--r--  1 root root 2190 Jun 29 15:20 hadoop-metrics2-hbase.properties
-rw-r--r--. 1 root root 4537 Apr 19 11:44 hbase-env.cmd
-rw-r--r--  1 root root 7535 Jun 29 15:02 hbase-env.sh
-rw-r--r--. 1 root root 2257 Apr 19 11:44 hbase-policy.xml
-rw-r--r--. 1 root root 2230 Jun 22 10:04 hbase-site.xml
lrwxrwxrwx  1 root root   50 Jul  1 17:01 hdfs-site.xml -> /bigdata_installed/hadoop/etc/hadoop/hdfs-site.xml
-rw-r--r--. 1 root root 4603 Apr 19 11:44 log4j.properties
-rw-r--r--. 1 root root   36 Jun 20 10:27 regionservers

```


2.将此改动同步到整个集群中

```
[root@hdp-node-01 conf]# for rs in `cat /bigdata_installed/hbase/conf/regionservers`;do
> rsync -avz /bigdata_installed/hbase/conf/hdfs-site.xml $rs:/bigdata_installed/hbase/conf/hdfs-site.xml
> done

```


3.重启hbase

```
[root@hdp-node-01 conf]# /bigdata_installed/hbase/bin/stop-hbase.sh 

[root@hdp-node-01 conf]# /bigdata_installed/hbase/bin/start-hbase.sh
```

再次查看web界面

![](/images/bigdata/hbase/dfs_replication_2.jpg)



# 处理zookeeper客户端连接错误

## 问题描述

有时在regionServer的日志文件中出现下面的错误，如下的zookeeper客户端连接错误

```
java.io.IOException:Connection reset by peer

```

## 操作步骤

登录到zookeeper上

1.在每个zookeeper的配置文件（zoo.cfg）添加如下内容

```
vim $ZOOKEEPRE_HOME/conf/zoo.cfg

maxClientCnxnx=60


# the maximum number of client connections.
# increase this if you need to handle more clients
#maxClientCnxns=60

```

2.重启zookeeper

```
$ZK_HOME/zkServer.sh stop

$ZK_HOME/zkServer.sh start

```


## 原因分析

这个错误通常是发生在hbase集群运行了一个MapReduce任务的情况下，zookeeper使用maxClientCnxns设置来限制一个客户端可向zookeeper仲裁团的一个成员发出的并发连接数，每台regionServer都是一个zookeeper客户端，如果一台regionServer的并发连接数超过了客户端最大连接数的限制，他就不能创建对zookeeper集群的新连接，这就是出现上述错误的原因


要修复这种错误，我们需要给maxClientCnxns设置一个更高的值，然后重新启动zookeeper


## 补充说明

从zookeeper3.4.0开始，maxClientCnxns的默认值已经改为了60，改默认值在很多应用场景下都可以满足要求

要查看某一客户端到指定zookeeper仲裁节点的当前连接数，执行下面的命令

```
echo "cons"|nc localhost 2181|grep "your.client.ip.address"|wc -l

#your.client.ip.address 是你实际客户端的IP地址

```

# 处理zookeeper回话过期错误

## 问题描述

在RegionServer日志中，“zookeeper会话过期”错误时该如何排除故障

![](/images/bigdata/hbase/session_expired.jpg)


这个问题至关重要，因为如果失去与zookeeper仲裁节点的连接，RegionServer或master就会自行关闭

## 操作步骤

1.检查hbase-env.sh文件，确保Hbase守护进程分配了足够的内存，对于重负载集群来说，默认分配的1G内存可能不够

vim $HBASE_HOME/conf/hbase-env.sh

```
export HBASE_HEAPSIZE=8000

```

2.运行vmstat命令来显示虚拟机内存的统计信息

```
[root@hdp-node-01 conf]# vmstat 1
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0   6588 137948 126704 466844    0    0     4    36   57   59  0  0 98  1  0
 0  0   6588 137916 126704 466844    0    0     0     0  158  283  0  0 99  0  0
 0  0   6588 137916 126712 466844    0    0     0    44  276  372  1  2 98  0  0
 0  0   6588 137908 126712 466844    0    0     0    36  197  350  0  1 99  0  0
 0  0   6588 137908 126712 466844    0    0     0     0  250  337  0  0 100  0  0

```

查看si(换入）和so(换出）这两个swap列，确认没有发生交换


3.使用jstat命令来显示Java垃圾回收（GC）的统计信息

```
[root@hdp-node-01 conf]# jps
17589 Jps
15375 DataNode
16777 HRegionServer
15271 NameNode
16669 HMaster
9813 QuorumPeerMain
15535 SecondaryNameNode
[root@hdp-node-01 conf]# jstat -gcutil 16777 1000
  S0     S1     E      O      P     YGC     YGCT    FGC    FGCT     GCT   
  2.47   0.00  83.67  73.27  31.07     72    3.507     2    0.023    3.530
  2.47   0.00  83.67  73.27  31.07     72    3.507     2    0.023    3.530
  2.47   0.00  94.72  73.27  31.07     72    3.507     2    0.023    3.530
  2.47   0.00  94.93  73.27  31.07     72    3.507     2    0.023    3.530
  2.47   0.00  94.96  73.27  31.07     72    3.507     2    0.023    3.530
  2.47   0.00  95.55  73.27  31.07     72    3.507     2    0.023    3.530
  2.47   0.00  95.79  73.27  31.07     72    3.507     2    0.023    3.530
  2.47   0.00  95.79  73.27  31.07     72    3.507     2    0.023    3.530


```

查看FGCT列，确认RegionServer没有发生长时间的full GC暂停


4.使用top命令查看CPU的统计信息，确认RegionServer线程有充足的CPU资源，MapReduce可能会使用大量CPU资源，从而导致RegionServer挂起并进入长时间的GC暂停状态


5.如果MapReduce占用的CPU资源过多，则需要考虑减少该RegionServer服务器上的map/reduce任务数，需要调整如下的几个属性

vim $HADOOP_HOME/etc/hadoop/mapred-site.xml
```
<property>
	<name>mapred.task.tasktracker.map.tasks.max</name>
	<value>2</value>
</property>

<property>
	<name>mapred.tasktarcker.reduce.tasks.maimun</name>
	<value>1</value>
</property>

```


6.考虑加大zookeeper的会话超时时间

vim $HBASE_HOME/conf/hbase-site.xml

```
<property>
	<name>zookeeper.session.timeout</name>
	<value>120000</value>
</property>
```


7.加大每个zookeeper仲裁节点的zookeeper会话最大超时时间，打开zoo.cfg文件

vim $ZK_HOME/conf/zoo.cfg

```
maxSessionTimeout=120000
```

8.如果修改了zoo.cfg文件需要重启每个zookeeper仲裁节点s


9.将修改过的文件同步到整个集群中，然后重新启动hadoop、hbase集群


## 运行原理

此错误通常发生在负载过重的hbase集群上，hbase的Master进程和RegionServer进程都是zookeeper的客户端，如果客户端无法再配置的时间内与zookeeper仲裁节点进行通信，连接超时，因而会出现此错误

zookeeper连接超时的两个最有可能的原因是：

* 长时间的JVM GC暂停
* 所配置的超时时间太短


从第1步到第5步，我们一直试图确定该错误是由GC造成的，hbase需要有大量的内存才能顺畅运行，对于重负载集群来说，默认分配的1GB的内存可能不够，因此，要将hbase-env.sh文件中的HBASE_HEAPSIZE属性的值修改为一个较高的值（例如8GB），但不能超过16GB，建议不让hbase的堆大小超过16GB的原因是：如果使用了一个非常大的堆大小，GC就需要很长时间才能完成，而这是我们必须避免的情况

要确保RegionServer不会交换，使用vmstat命令可以看到是否发生了交换，在第2步中，我们使用vmstat命令来每隔1s显示一次虚拟内存的统计信息，为了避免交换，需要修改内核参数vm.swappiness的值

jstat是一个Java虚拟机的统计监测工具，在第3步中，我们使用了-gcutil选项来显示指定Java进程的GC的统计信息（每隔1s显示一次），FGCT列输出的就是全部GC的时间总和，检查此列可确定是偶发生了长时间的GC暂停


长时间的GC暂停的另一个原因是：RegionServer进程可能没有足够的CPU资源，当在hbase集群上运行了负载很重的MapReduce任务的时候，尤其容易出现这种情况，在这种情况下，如果运行有负载很重的MapReduce任务，则需要使用mapred.tasktracker.map.tasks.maximum和mapred.tasktarcker.reduce.tasks.maimum这两个MapReduce配置来控制一个TaskTracker上同时产生的map/reduce任务的数量

如果想要加大zookeeper的会话超时时间，可以设置hbase-site.xml文件中的zookeeper.session.timeout参数和zookeeper配置文件中的（zoo.cfg）中的maxSessionTimeout选项，maxSessionTimeout是zookeeper的服务器端配置选项，他是客户端会话超时的时间上限，所以该选项的值必须大于hbase的zookeeper.session.timeout参数的值


**请注意调高时间意味着，至少要经过所设定的时间之后，集群才会对发生故障的RegionServer进行故障切换，你要考虑好自己的系统是否能接受这种高超时**


# 处理EC2上的hbase启动错误





